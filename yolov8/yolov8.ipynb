{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209c7cac-7550-4284-aedc-7f02b87c6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e273d15-da0b-494b-b52d-13460564bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from math import sqrt\n",
    "import cv2 as cv\n",
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from os import makedirs\n",
    "from os.path import basename, splitext\n",
    "import glob\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a209a6a1-2469-4f9e-883d-d7c96ed793e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(fp: str, prune_ext: bool = True) -> str:\n",
    "    \"\"\"Get the filename of a filepath.\n",
    "\n",
    "    Args:\n",
    "        fp: Filepath.\n",
    "        prune_ext: Remove extension.\n",
    "    \n",
    "    Returns:\n",
    "        Filename.\n",
    "\n",
    "    \"\"\"\n",
    "    fn = basename(fp)\n",
    "\n",
    "    if prune_ext:\n",
    "        fn = splitext(fn)[0]\n",
    "\n",
    "    return fn\n",
    "\n",
    "def imread(fp: str, fmt: str = 'rgb', grayscale: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read image file*.\n",
    "\n",
    "    * Only supports RGB images currently, in the future we will look add \n",
    "    support for RGBA and grayscale images.\n",
    "    \n",
    "    Args:\n",
    "        fp (str): Filepath to image.\n",
    "        fmt (str): Format to read image as: 'rgb', 'bgr', 'gray'.\n",
    "        grayscale (bool): Will be deprecated in the future, similar behavior can\n",
    "            be achieved by setting format to 'gray'. Read image as grayscale.\n",
    "    \n",
    "    Returns:\n",
    "        (numpy.ndarray) Image as numpy array.\n",
    "    \n",
    "    \"\"\"\n",
    "    assert fmt in ('rgb', 'bgr', 'gray'), \"fmt must be 'rgb', 'bgr' or 'gray'.\"\n",
    "    \n",
    "    if grayscale:\n",
    "        return cv.imread(fp, cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img = cv.imread(fp)\n",
    "    \n",
    "    if fmt == 'rgb':\n",
    "        return cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    elif fmt == 'gray':\n",
    "        return cv.cvtColor(img, cv.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def blob_detect(fp: str, kwargs: dict, r_thr: int = 5, plot: bool = False,\n",
    "                figsize: Tuple[int, int] = (7, 7), save_dir: str = None) -> str:\n",
    "    \"\"\"Detect blobs in an image, .\n",
    "    \n",
    "    Args:\n",
    "        fp: Filepath of image.\n",
    "        kwargs: Key-word arguments passed to skimage.feature.blob_log.\n",
    "        r_thr: Remove blobs with radii smaller than this value.\n",
    "        plot: Plot figures if True.\n",
    "        figsize: Size of figures to plot.\n",
    "        save_dir: Directory to save label text files.\n",
    "    \n",
    "    Returns:\n",
    "        The blob coordinates in string format.\n",
    "    \n",
    "    \"\"\"\n",
    "    img = imread(fp, grayscale=True)        \n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    if plot:\n",
    "        # Draw on the image.\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title('Image', fontsize=16)\n",
    "        plt.show()\n",
    "    \n",
    "    print(f'Size of image: {w} x {h}.')\n",
    "    blobs = blob_log(img, **kwargs)\n",
    "    \n",
    "    # Add radious in their column.\n",
    "    blobs[:, 2] = blobs[:, 2] * sqrt(2)\n",
    "    \n",
    "    print(f'{len(blobs)} number of blobs detected.')\n",
    "    \n",
    "    # Filter the blobs: \n",
    "    if plot:   \n",
    "        img = cv.cvtColor(img, cv.COLOR_GRAY2RGB)\n",
    "    lines = ''\n",
    "    \n",
    "    # Filter blobs.\n",
    "    blobs = [blob for blob in blobs if blob[2] > r_thr]\n",
    "    \n",
    "    print(f'{len(blobs)} number of blobs after radii filtering.')\n",
    "\n",
    "    for blob in blobs:\n",
    "        y, x, r = blob.astype(int)\n",
    "        \n",
    "        x1, y1 = x - r, y - r\n",
    "        x2, y2 = x + r, y + r\n",
    "        \n",
    "        lines += f'0 {x / w:4f} {y / h:4f} {(x2-x1) / w:4f} {(y2-y1) / h:4f}\\n'\n",
    "        \n",
    "        if plot:\n",
    "            img = cv.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "        \n",
    "    if save_dir is not None:\n",
    "        # Save the file.\n",
    "        with open(join(save_dir, f'{get_filename(fp)}.txt'), 'w') as fh:\n",
    "            fh.write(lines.strip())\n",
    "        \n",
    "    if plot:\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title('Blobs', fontsize=16)\n",
    "        plt.show()\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5c509a3-f899-4a50-a7b6-2e43434c48d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 PNG files.\n"
     ]
    }
   ],
   "source": [
    "src_dir = './datasets/yolov8/images'\n",
    "img_fps = sorted([fp for fp in glob.glob(join(src_dir, '*.png'))])\n",
    "src_dir_labels = './datasets/yolov8'\n",
    "if not img_fps:\n",
    "    print(\"No PNG files found in the specified directory.\")\n",
    "else:\n",
    "    label_dir = join(src_dir_labels, 'labels')\n",
    "    makedirs(label_dir, exist_ok=True)\n",
    "    print(f\"Found {len(img_fps)} PNG files.\")\n",
    "label_dir = join(src_dir_labels, 'labels')\n",
    "makedirs(label_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e62545b-62f0-428b-bfab-e0cfaff466ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cee67576304f2ab4dc2b417c3f3121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of image: 3711 x 3735.\n",
      "55410 number of blobs detected.\n",
      "1477 number of blobs after radii filtering.\n",
      "Size of image: 4186 x 4212.\n",
      "36301 number of blobs detected.\n",
      "1680 number of blobs after radii filtering.\n",
      "Size of image: 2894 x 2366.\n",
      "8161 number of blobs detected.\n",
      "534 number of blobs after radii filtering.\n",
      "Size of image: 3251 x 3718.\n",
      "60905 number of blobs detected.\n",
      "2032 number of blobs after radii filtering.\n",
      "Size of image: 3225 x 3282.\n",
      "4254 number of blobs detected.\n",
      "1139 number of blobs after radii filtering.\n",
      "Size of image: 3241 x 2791.\n",
      "4964 number of blobs detected.\n",
      "779 number of blobs after radii filtering.\n",
      "Size of image: 3695 x 2813.\n",
      "8039 number of blobs detected.\n",
      "1117 number of blobs after radii filtering.\n",
      "Size of image: 2309 x 1896.\n",
      "2475 number of blobs detected.\n",
      "321 number of blobs after radii filtering.\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'max_sigma': 30, \n",
    "    'num_sigma': 15, \n",
    "    'threshold': 0.05\n",
    "}\n",
    "\n",
    "for fp in tqdm(img_fps):\n",
    "    _ = blob_detect(fp, kwargs=kwargs, save_dir=label_dir, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47d4997-3a1e-40fb-9da0-1ef591896918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_yolo_label, im_to_txt_path, corners_to_polygon, tile_roi_with_labels, tile_roi_with_labels_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca3896d-a51f-4c2e-b898-4319eaeef2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from girder_client import GirderClient\n",
    "from multiprocessing import Pool\n",
    "from typing import List, Union, Tuple\n",
    "from pandas import DataFrame, concat\n",
    "from typing import Tuple\n",
    "from geopandas import GeoDataFrame\n",
    "from os import makedirs\n",
    "from os.path import isfile, join\n",
    "from typing import Union, Tuple\n",
    "import numpy as np\n",
    "from os.path import basename, splitext\n",
    "import torch\n",
    "\n",
    "def imwrite(fp: str, img: np.ndarray, grayscale: bool = False):\n",
    "    \"\"\"Write image to file.\n",
    "    \n",
    "    Args:\n",
    "        fp: Filepath to save image.\n",
    "        img: Image to save.\n",
    "        grayscale: True to save image as a grayscale image, otherwise it is\n",
    "            saved as an RGB image.\n",
    "    \n",
    "    \"\"\"\n",
    "    if grayscale:\n",
    "        cv.imwrite(fp, img)\n",
    "    else:\n",
    "        cv.imwrite(fp, cv.cvtColor(img, cv.COLOR_RGB2BGR))\n",
    "\n",
    "def imread(fp: str, fmt: str = 'rgb', grayscale: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read image file*.\n",
    "\n",
    "    * Only supports RGB images currently, in the future we will look add \n",
    "    support for RGBA and grayscale images.\n",
    "    \n",
    "    Args:\n",
    "        fp (str): Filepath to image.\n",
    "        fmt (str): Format to read image as: 'rgb', 'bgr', 'gray'.\n",
    "        grayscale (bool): Will be deprecated in the future, similar behavior can\n",
    "            be achieved by setting format to 'gray'. Read image as grayscale.\n",
    "    \n",
    "    Returns:\n",
    "        (numpy.ndarray) Image as numpy array.\n",
    "    \n",
    "    \"\"\"\n",
    "    assert fmt in ('rgb', 'bgr', 'gray'), \"fmt must be 'rgb', 'bgr' or 'gray'.\"\n",
    "    \n",
    "    if grayscale:\n",
    "        return cv.imread(fp, cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img = cv.imread(fp)\n",
    "    \n",
    "    if fmt == 'rgb':\n",
    "        return cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    elif fmt == 'gray':\n",
    "        return cv.cvtColor(img, cv.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        return img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c079d95d-11a5-42b0-b387-89f7bae97bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f1b832efd44187b2e23915354da8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp</th>\n",
       "      <th>roi_fp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>tile_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/tile...</td>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/imag...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/tile...</td>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/imag...</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/tile...</td>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/imag...</td>\n",
       "      <td>0</td>\n",
       "      <td>1920</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/tile...</td>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/imag...</td>\n",
       "      <td>0</td>\n",
       "      <td>2880</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/tile...</td>\n",
       "      <td>/code/ml-tissue-detection/datasets/yolov8/imag...</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fp  \\\n",
       "0  /code/ml-tissue-detection/datasets/yolov8/tile...   \n",
       "1  /code/ml-tissue-detection/datasets/yolov8/tile...   \n",
       "2  /code/ml-tissue-detection/datasets/yolov8/tile...   \n",
       "3  /code/ml-tissue-detection/datasets/yolov8/tile...   \n",
       "4  /code/ml-tissue-detection/datasets/yolov8/tile...   \n",
       "\n",
       "                                              roi_fp    x     y  tile_size  \n",
       "0  /code/ml-tissue-detection/datasets/yolov8/imag...    0     0       1280  \n",
       "1  /code/ml-tissue-detection/datasets/yolov8/imag...    0   960       1280  \n",
       "2  /code/ml-tissue-detection/datasets/yolov8/imag...    0  1920       1280  \n",
       "3  /code/ml-tissue-detection/datasets/yolov8/imag...    0  2880       1280  \n",
       "4  /code/ml-tissue-detection/datasets/yolov8/imag...  960     0       1280  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps = glob.glob(\"/code/ml-tissue-detection/datasets/yolov8/images/*.png\")\n",
    "\n",
    "SAVE_DIR= '/code/ml-tissue-detection/datasets/yolov8'\n",
    "tiles_dir = join(SAVE_DIR, 'tiles')\n",
    "\n",
    "tiles_df = tile_roi_with_labels_wrapper(\n",
    "    fps,\n",
    "    tiles_dir,\n",
    "    tile_size=1280,\n",
    "    stride=960,\n",
    "    fill=0,\n",
    "    notebook=True,\n",
    "    grayscale=False\n",
    ")\n",
    "\n",
    "tiles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb5e435-8c24-4648-b663-8c58b9001e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "fps = sorted(fps)\n",
    "train_fps, val_fps = train_test_split(fps, train_size=0.8)\n",
    "\n",
    "val_txt_fp = join(SAVE_DIR, 'val.txt')\n",
    "\n",
    "with open(join(SAVE_DIR, 'dataset.yaml'), 'w') as fh:\n",
    "    yaml.safe_dump(\n",
    "        {'nc': 1, 'names': ['nuclei'], 'path': SAVE_DIR, 'train': 'train.txt',\n",
    "         'val': 'val.txt'}, \n",
    "        fh\n",
    "    )\n",
    "    \n",
    "with open(join(SAVE_DIR, 'train.txt'), 'w') as fh:\n",
    "    fh.write(\n",
    "        '\\n'.join(tiles_df[tiles_df.roi_fp.isin(train_fps)].fp.tolist()).strip()\n",
    "    )\n",
    "    \n",
    "with open(join(SAVE_DIR, 'val.txt'), 'w') as fh:\n",
    "    fh.write(\n",
    "        '\\n'.join(tiles_df[tiles_df.roi_fp.isin(val_fps)].fp.tolist()).strip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41ba815-6719-4693-81b7-b3d6e4a2f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/ray/anaconda3/lib/python3.9/site-packages (8.0.211)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (1.26.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (9.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (0.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: psutil in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (6.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ray/anaconda3/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2023.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ray/anaconda3/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.2.140)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ray/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ray/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49e05f7-94c2-455c-992c-36dbf57e8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9138f372-34d1-44c3-ae36-b76ad4ed6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.yaml').load('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b5ae03-b451-4321-8638-9c565cd41eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.215 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.211 ðŸš€ Python-3.9.15 torch-2.1.0+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=./datasets/yolov8/dataset.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train25, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train25\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdagutman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/code/ml-tissue-detection/wandb/run-20231121_200254-zuuei7fb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dagutman/YOLOv8/runs/zuuei7fb' target=\"_blank\">train25</a></strong> to <a href='https://wandb.ai/dagutman/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dagutman/YOLOv8' target=\"_blank\">https://wandb.ai/dagutman/YOLOv8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dagutman/YOLOv8/runs/zuuei7fb' target=\"_blank\">https://wandb.ai/dagutman/YOLOv8/runs/zuuei7fb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /code/ml-tissue-detection/datasets/yolov8/tiles/labels... 87 images, 0 backgrounds, 0 corrupt: 100%|\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /code/ml-tissue-detection/datasets/yolov8/tiles/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /code/ml-tissue-detection/datasets/yolov8/tiles/labels... 21 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆ\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /code/ml-tissue-detection/datasets/yolov8/tiles/labels.cache\n",
      "Plotting labels to runs/detect/train25/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train25\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      4.46G      3.352      3.731        1.2        979        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:51<00:00,  8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783    0.00111    0.00185   0.000557   0.000151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50      5.42G      2.923      3.522      1.089        978        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783    0.00143    0.00238   0.000723   0.000289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50      4.79G      2.432      2.149     0.9176        953        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.163      0.272      0.128     0.0363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50      5.62G      2.291      1.373     0.8908       1479        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783       0.22      0.367      0.195     0.0634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50      5.39G      2.144      1.195     0.8806       1515        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.303      0.504      0.442      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      5.34G      2.091      1.118     0.8701       1266        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.367      0.612      0.579      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50      5.93G      2.006      1.087     0.8589       1232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.397      0.661      0.628      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50      5.77G      1.982      1.046     0.8555        996        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.394      0.657      0.643      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50      5.79G      2.007      1.066     0.8651       1022        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.426      0.709      0.684      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50      5.96G      1.926     0.9924     0.8467       1214        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.422      0.703      0.666      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50      6.55G       1.91      1.001     0.8548       1527        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.435      0.725      0.703      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50      5.38G      1.883      1.023     0.8549       1187        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.432       0.72      0.696      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50      4.25G      1.835     0.9864     0.8505       1170        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.457      0.762      0.734      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50      5.04G      1.872     0.9745     0.8512       1447        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.696      0.746      0.731      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50      4.26G      1.922     0.9995     0.8457       1389        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.798      0.655      0.743      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50      5.71G       1.88     0.9963     0.8445       1232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.717      0.715      0.742      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50      4.18G      1.786     0.9438     0.8422       1080        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.735      0.731      0.766      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50       4.7G      1.752     0.9525     0.8433        830        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.759      0.755      0.789      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50      5.94G      1.795     0.9474     0.8334       1147        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.763      0.772      0.801      0.361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50       5.9G      1.753     0.9432     0.8398        897        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.777      0.774      0.801       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50      3.91G      1.725     0.9151      0.842        737        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.798      0.786      0.821      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50      4.39G      1.802     0.9279     0.8403       1131        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.768      0.768      0.781      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50      6.15G       1.84     0.9554     0.8382       1412        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.786      0.794      0.818      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50      3.97G      1.747     0.9145     0.8397       1267        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.778      0.797      0.808       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50      5.72G      1.686     0.9101     0.8466       1180        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.791      0.808      0.828      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50      6.32G      1.732      0.898     0.8322       1558        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.785      0.806       0.83      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50      6.88G      1.725     0.9135     0.8351       1053        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.791       0.81      0.835      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50      6.04G      1.692     0.8799      0.836       1464        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.786      0.804      0.821      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50      5.39G      1.653     0.8637     0.8355        973        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.797      0.812      0.838      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50      5.97G      1.634     0.8642     0.8316       1078        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783       0.82      0.793      0.843      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50      6.01G      1.684     0.8901     0.8355       1263        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.828      0.796      0.848      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50      5.66G      1.678      0.913      0.831       1162        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.812      0.814      0.848      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50      4.58G      1.627     0.8546     0.8321        992        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.814      0.818      0.848      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50      4.02G      1.611     0.8841     0.8398       1470        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.807      0.826      0.841      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50      5.19G      1.654     0.8793     0.8379       1141        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.805      0.822      0.839       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50      5.55G      1.732     0.9056     0.8354       1636        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.801      0.815      0.839      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50      5.11G       1.68      0.885      0.835       1439        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.802      0.819      0.845      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50      5.18G      1.678     0.9056     0.8361        844        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.804      0.823       0.85      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50      4.03G      1.613     0.8469     0.8307       1075        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.809       0.82      0.848       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50      6.65G      1.718     0.8746     0.8365       1402        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.812      0.802      0.841      0.444\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50       3.7G      1.558     0.9069      0.833        637        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:43<00:00,  7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.807      0.807      0.838      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50      3.97G      1.542     0.8975     0.8372        706        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783       0.79      0.785      0.806      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50      3.03G       1.54     0.8988     0.8278        602        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.779      0.792      0.802      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50      4.03G      1.509     0.8869     0.8307        690        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.767      0.777      0.781      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50      3.87G      1.496     0.8801     0.8315        450        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.761      0.771      0.776      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50      4.38G       1.51     0.8564     0.8328        788        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.775      0.788        0.8      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50      3.57G      1.561     0.8824      0.832        646        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.799      0.807      0.829      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50      3.36G      1.462     0.8309     0.8295        727        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.809      0.827      0.856      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50      3.05G      1.501     0.8357     0.8284        940        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783       0.81      0.827      0.857      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50      3.61G       1.51     0.8606      0.827        694        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.818      0.819      0.857      0.475\n",
      "\n",
      "50 epochs completed in 0.071 hours.\n",
      "Optimizer stripped from runs/detect/train25/weights/last.pt, 6.3MB\n",
      "Optimizer stripped from runs/detect/train25/weights/best.pt, 6.3MB\n",
      "\n",
      "Validating runs/detect/train25/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.211 ðŸš€ Python-3.9.15 torch-2.1.0+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:0\n",
      "                   all         21       3783      0.809      0.826      0.857      0.481\n",
      "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train25\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–‚â–ƒâ–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–‚â–‚â–„â–…â–…â–…â–†â–…â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–â–â–ƒâ–„â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>train/box_loss</td><td>â–ˆâ–†â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>train/cls_loss</td><td>â–ˆâ–‡â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/dfl_loss</td><td>â–ˆâ–†â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val/box_loss</td><td>â–ˆâ–ˆâ–†â–†â–…â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–ƒâ–ƒâ–â–â–‚â–‚â–â–â–‚â–‚â–â–</td></tr><tr><td>val/cls_loss</td><td>â–ˆâ–ˆâ–‡â–†â–„â–„â–„â–„â–„â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val/dfl_loss</td><td>â–ˆâ–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0001</td></tr><tr><td>lr/pg1</td><td>0.0001</td></tr><tr><td>lr/pg2</td><td>0.0001</td></tr><tr><td>metrics/mAP50(B)</td><td>0.8569</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.48067</td></tr><tr><td>metrics/precision(B)</td><td>0.80918</td></tr><tr><td>metrics/recall(B)</td><td>0.82613</td></tr><tr><td>model/GFLOPs</td><td>8.194</td></tr><tr><td>model/parameters</td><td>3011043</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>4.799</td></tr><tr><td>train/box_loss</td><td>1.5103</td></tr><tr><td>train/cls_loss</td><td>0.86062</td></tr><tr><td>train/dfl_loss</td><td>0.82697</td></tr><tr><td>val/box_loss</td><td>1.51041</td></tr><tr><td>val/cls_loss</td><td>0.80339</td></tr><tr><td>val/dfl_loss</td><td>0.82369</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train25</strong> at: <a href='https://wandb.ai/dagutman/YOLOv8/runs/zuuei7fb' target=\"_blank\">https://wandb.ai/dagutman/YOLOv8/runs/zuuei7fb</a><br/>Synced 6 W&B file(s), 20 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231121_200254-zuuei7fb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.train(data='./datasets/yolov8/dataset.yaml', epochs=50, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0129436a-c18a-4324-b8f5-8ea0a4a10d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.211 ðŸš€ Python-3.9.15 torch-2.1.0+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /code/ml-tissue-detection/datasets/yolov8/tiles/labels.cache... 21 images, 0 backgrounds, 0 corrupt: 1\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:3\n",
      "                   all         21       3783      0.812      0.829      0.861      0.483\n",
      "Speed: 0.2ms preprocess, 9.8ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train252\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "503743e9-8a53-49cc-93c6-74cce843d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ 'hide_conf' is deprecated and will be removed in 'ultralytics 8.2' in the future. Please use 'show_conf' instead.\n",
      "WARNING âš ï¸ 'hide_labels' is deprecated and will be removed in 'ultralytics 8.2' in the future. Please use 'show_labels' instead.\n",
      "\n",
      "image 1/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x0y0.png: 640x640 178 nucleis, 14.4ms\n",
      "image 2/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x0y1920.png: 640x640 113 nucleis, 12.0ms\n",
      "image 3/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x0y2880.png: 640x640 57 nucleis, 11.9ms\n",
      "image 4/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x0y960.png: 640x640 131 nucleis, 11.8ms\n",
      "image 5/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x1920y0.png: 640x640 200 nucleis, 12.0ms\n",
      "image 6/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x1920y1920.png: 640x640 105 nucleis, 11.9ms\n",
      "image 7/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x1920y2880.png: 640x640 98 nucleis, 11.8ms\n",
      "image 8/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x1920y960.png: 640x640 104 nucleis, 11.9ms\n",
      "image 9/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x2880y0.png: 640x640 90 nucleis, 11.8ms\n",
      "image 10/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x2880y1920.png: 640x640 30 nucleis, 11.8ms\n",
      "image 11/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x2880y2880.png: 640x640 22 nucleis, 11.8ms\n",
      "image 12/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x2880y960.png: 640x640 41 nucleis, 11.7ms\n",
      "image 13/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x960y0.png: 640x640 193 nucleis, 11.8ms\n",
      "image 14/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x960y1920.png: 640x640 139 nucleis, 11.8ms\n",
      "image 15/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x960y2880.png: 640x640 93 nucleis, 11.8ms\n",
      "image 16/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E15-46 IGHM GFAP-x960y960.png: 640x640 143 nucleis, 11.9ms\n",
      "image 17/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x0y0.png: 640x640 31 nucleis, 11.9ms\n",
      "image 18/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x0y1920.png: 640x640 131 nucleis, 11.8ms\n",
      "image 19/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x0y2880.png: 640x640 155 nucleis, 11.8ms\n",
      "image 20/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x0y3840.png: 640x640 41 nucleis, 11.8ms\n",
      "image 21/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x0y960.png: 640x640 98 nucleis, 11.7ms\n",
      "image 22/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x1920y0.png: 640x640 205 nucleis, 11.7ms\n",
      "image 23/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x1920y1920.png: 640x640 157 nucleis, 11.9ms\n",
      "image 24/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x1920y2880.png: 640x640 124 nucleis, 12.0ms\n",
      "image 25/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x1920y3840.png: 640x640 20 nucleis, 11.7ms\n",
      "image 26/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x1920y960.png: 640x640 168 nucleis, 11.7ms\n",
      "image 27/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x2880y0.png: 640x640 205 nucleis, 11.8ms\n",
      "image 28/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x2880y1920.png: 640x640 161 nucleis, 12.0ms\n",
      "image 29/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x2880y2880.png: 640x640 120 nucleis, 11.8ms\n",
      "image 30/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x2880y3840.png: 640x640 23 nucleis, 11.7ms\n",
      "image 31/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x2880y960.png: 640x640 186 nucleis, 11.6ms\n",
      "image 32/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x3840y0.png: 640x640 74 nucleis, 11.8ms\n",
      "image 33/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x3840y1920.png: 640x640 48 nucleis, 11.6ms\n",
      "image 34/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x3840y2880.png: 640x640 27 nucleis, 11.6ms\n",
      "image 35/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x3840y960.png: 640x640 57 nucleis, 11.5ms\n",
      "image 36/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x960y0.png: 640x640 204 nucleis, 11.7ms\n",
      "image 37/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x960y1920.png: 640x640 173 nucleis, 13.1ms\n",
      "image 38/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x960y2880.png: 640x640 129 nucleis, 12.4ms\n",
      "image 39/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x960y3840.png: 640x640 27 nucleis, 11.8ms\n",
      "image 40/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/7-27-2023 E20-18 IGHM GFAP-x960y960.png: 640x640 216 nucleis, 11.8ms\n",
      "image 41/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-10-2023 E20-71 GFAP IGHM DAPI-x0y0.png: 640x640 143 nucleis, 11.8ms\n",
      "image 42/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-10-2023 E20-71 GFAP IGHM DAPI-x0y1920.png: 640x640 38 nucleis, 12.1ms\n",
      "image 43/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-10-2023 E20-71 GFAP IGHM DAPI-x0y960.png: 640x640 111 nucleis, 11.6ms\n",
      "image 44/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-10-2023 E20-71 GFAP IGHM DAPI-x1920y0.png: 640x640 103 nucleis, 12.2ms\n",
      "image 45/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-10-2023 E20-71 GFAP IGHM DAPI-x1920y1920.png: 640x640 33 nucleis, 11.7ms\n",
      "image 46/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-10-2023 E20-71 GFAP IGHM DAPI-x1920y960.png: 640x640 83 nucleis, 12.1ms\n",
      "image 47/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-10-2023 E20-71 GFAP IGHM DAPI-x960y0.png: 640x640 167 nucleis, 11.7ms\n",
      "image 48/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-10-2023 E20-71 GFAP IGHM DAPI-x960y1920.png: 640x640 49 nucleis, 13.0ms\n",
      "image 49/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-10-2023 E20-71 GFAP IGHM DAPI-x960y960.png: 640x640 140 nucleis, 11.7ms\n",
      "image 50/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x0y0.png: 640x640 272 nucleis, 16.8ms\n",
      "image 51/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x0y1920.png: 640x640 230 nucleis, 11.9ms\n",
      "image 52/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x0y2880.png: 640x640 141 nucleis, 13.3ms\n",
      "image 53/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x0y960.png: 640x640 267 nucleis, 11.8ms\n",
      "image 54/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x1920y0.png: 640x640 289 nucleis, 13.5ms\n",
      "image 55/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x1920y1920.png: 640x640 286 nucleis, 12.8ms\n",
      "image 56/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x1920y2880.png: 640x640 136 nucleis, 12.2ms\n",
      "image 57/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x1920y960.png: 640x640 283 nucleis, 12.6ms\n",
      "image 58/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x2880y0.png: 640x640 80 nucleis, 11.9ms\n",
      "image 59/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x2880y1920.png: 640x640 70 nucleis, 11.6ms\n",
      "image 60/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x2880y960.png: 640x640 69 nucleis, 11.7ms\n",
      "image 61/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x960y0.png: 640x640 297 nucleis, 11.6ms\n",
      "image 62/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x960y1920.png: 640x640 261 nucleis, 12.0ms\n",
      "image 63/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x960y2880.png: 640x640 161 nucleis, 12.3ms\n",
      "image 64/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/8-3-2023 E09-164 IGHM GFAP 63X-x960y960.png: 640x640 300 nucleis, 13.1ms\n",
      "image 65/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x0y0.png: 640x640 168 nucleis, 12.9ms\n",
      "image 66/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x0y1920.png: 640x640 199 nucleis, 13.4ms\n",
      "image 67/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x0y2880.png: 640x640 60 nucleis, 13.2ms\n",
      "image 68/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x0y960.png: 640x640 210 nucleis, 13.1ms\n",
      "image 69/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x1920y0.png: 640x640 193 nucleis, 13.2ms\n",
      "image 70/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x1920y1920.png: 640x640 174 nucleis, 13.1ms\n",
      "image 71/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x1920y2880.png: 640x640 55 nucleis, 13.2ms\n",
      "image 72/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x1920y960.png: 640x640 159 nucleis, 13.1ms\n",
      "image 73/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x2880y0.png: 640x640 66 nucleis, 13.4ms\n",
      "image 74/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x2880y1920.png: 640x640 58 nucleis, 13.0ms\n",
      "image 75/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x2880y960.png: 640x640 47 nucleis, 13.2ms\n",
      "image 76/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x960y0.png: 640x640 188 nucleis, 13.1ms\n",
      "image 77/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x960y1920.png: 640x640 176 nucleis, 13.3ms\n",
      "image 78/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x960y2880.png: 640x640 50 nucleis, 13.3ms\n",
      "image 79/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023  E15-06 IGHM 568 GFAP FITC DAPI-x960y960.png: 640x640 203 nucleis, 13.1ms\n",
      "image 80/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x0y0.png: 640x640 124 nucleis, 10.6ms\n",
      "image 81/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x0y1920.png: 640x640 73 nucleis, 10.3ms\n",
      "image 82/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x0y960.png: 640x640 144 nucleis, 10.4ms\n",
      "image 83/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x1920y0.png: 640x640 138 nucleis, 11.5ms\n",
      "image 84/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x1920y1920.png: 640x640 70 nucleis, 10.4ms\n",
      "image 85/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x1920y960.png: 640x640 111 nucleis, 10.4ms\n",
      "image 86/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x2880y0.png: 640x640 21 nucleis, 10.4ms\n",
      "image 87/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x2880y960.png: 640x640 27 nucleis, 10.3ms\n",
      "image 88/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x960y0.png: 640x640 215 nucleis, 10.5ms\n",
      "image 89/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x960y1920.png: 640x640 113 nucleis, 10.4ms\n",
      "image 90/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-33 IGHM 568 GFAP FITC DAPI-x960y960.png: 640x640 175 nucleis, 10.2ms\n",
      "image 91/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x0y0.png: 640x640 151 nucleis, 10.4ms\n",
      "image 92/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x0y1920.png: 640x640 122 nucleis, 10.4ms\n",
      "image 93/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x0y960.png: 640x640 165 nucleis, 10.4ms\n",
      "image 94/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x1920y0.png: 640x640 183 nucleis, 10.4ms\n",
      "image 95/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x1920y1920.png: 640x640 114 nucleis, 10.5ms\n",
      "image 96/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x1920y960.png: 640x640 142 nucleis, 10.3ms\n",
      "image 97/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x2880y0.png: 640x640 84 nucleis, 10.4ms\n",
      "image 98/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x2880y1920.png: 640x640 61 nucleis, 10.4ms\n",
      "image 99/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x2880y960.png: 640x640 90 nucleis, 10.4ms\n",
      "image 100/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x960y0.png: 640x640 242 nucleis, 10.4ms\n",
      "image 101/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x960y1920.png: 640x640 116 nucleis, 10.4ms\n",
      "image 102/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E11-73 IGHM 568 GFAP FITC DAPI-x960y960.png: 640x640 194 nucleis, 10.4ms\n",
      "image 103/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E14-06 IGHM 568 GFAP FTIC DAPI-x0y0.png: 640x640 124 nucleis, 10.4ms\n",
      "image 104/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E14-06 IGHM 568 GFAP FTIC DAPI-x0y960.png: 640x640 85 nucleis, 10.5ms\n",
      "image 105/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E14-06 IGHM 568 GFAP FTIC DAPI-x1920y0.png: 640x640 35 nucleis, 10.4ms\n",
      "image 106/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E14-06 IGHM 568 GFAP FTIC DAPI-x1920y960.png: 640x640 31 nucleis, 10.3ms\n",
      "image 107/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E14-06 IGHM 568 GFAP FTIC DAPI-x960y0.png: 640x640 103 nucleis, 10.3ms\n",
      "image 108/108 /code/ml-tissue-detection/datasets/yolov8/tiles/images/9-12-2023 E14-06 IGHM 568 GFAP FTIC DAPI-x960y960.png: 640x640 93 nucleis, 10.4ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "108 labels saved to runs/detect/predict9/labels\n"
     ]
    }
   ],
   "source": [
    "fp = '/code/ml-tissue-detection/datasets/yolov8/tiles/images/'\n",
    "model = YOLO('/code/ml-tissue-detection/runs/detect/train242/weights/best.pt')\n",
    "\n",
    "results = model.predict(\n",
    "    fp,\n",
    "    save_txt=True, save_conf=True, save=True, hide_conf=True, hide_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88ccd0-c992-4bed-a51a-e56b2b24a297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
