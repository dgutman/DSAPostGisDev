{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de5748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Will generate image histogram and stats at 1.25 X to test implementation of feature vector / simpel clusting\n",
    "import random\n",
    "import large_image, requests\n",
    "import numpy as np\n",
    "import time, glob, os\n",
    "imagePath = \"TCGA-3L-AA1B-01A-01-TS1.9C415218-D5B4-4945-B243-F42A4C8C0484.svs\"\n",
    "\n",
    "\n",
    "fastApiUrl=\"http://dsapostgisapi:82/\"\n",
    "dsaApiUrl = \"https://wsi-deid.pathology.emory.edu/api/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b60079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "## For now I am using locally storage images to make thngs faster\n",
    "imageList = os.listdir(\"SmallSampleFiles/\")\n",
    "\n",
    "print(len(imageList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b18b6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    " \n",
    "def split_list(input_list, chunk_size):\n",
    "  # Create a deque object from the input list\n",
    "  deque_obj = deque(input_list)\n",
    "  # While the deque object is not empty\n",
    "  while deque_obj:\n",
    "      # Pop chunk_size elements from the left side of the deque object\n",
    "      # and append them to the chunk list\n",
    "      chunk = []\n",
    "      for _ in range(chunk_size):\n",
    "        if deque_obj:\n",
    "          chunk.append(deque_obj.popleft())\n",
    "         \n",
    "      # Yield the chunk\n",
    "      yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c1bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookupPostgisImageId( imageName, dsaApiUrl):\n",
    "    r = requests.get(fastApiUrl+\"lookupImage\", params={\"imageName\":imageName,\"dsaApiUrl\":dsaApiUrl})\n",
    "    #print(r.json())\n",
    "    return r.json()\n",
    "\n",
    "def generateRGBGrid(imageName, dsaApiUrl, magnification=1.25, tileSize=\"native\", opType=\"tileHist\"):\n",
    "    \n",
    "    ## For now I am using local images, so I need to map the imageName to a localFilePath\n",
    "    \n",
    "    imageInfo = lookupPostgisImageId(imageName, dsaApiUrl)\n",
    "    \n",
    "    if not imageInfo:\n",
    "        print(\"Image is not synced in local database\")\n",
    "        return\n",
    "        \n",
    "    imagePath = os.path.join(\"SmallSampleFiles\",imageName)\n",
    "    \n",
    "    ## Create a largeImage Pointed\n",
    "    ts = large_image.open(imagePath)\n",
    "    computationStats = {\"imageName\": imageName, \"imagePath\":imagePath,\"opType\": opType}\n",
    "    tilesProcessed = 0\n",
    "    bytesRead = 0\n",
    "    \n",
    "    gridData = []\n",
    "\n",
    "    ## Compute start time of algorithm\n",
    "    st = time.time()\n",
    "    computationStats[\"startTime\"] = st\n",
    "\n",
    "    if tileSize == \"native\":\n",
    "        tileWidth = ts.tileWidth\n",
    "        tileHeight = ts.tileHeight\n",
    "    else:\n",
    "        tileWidth = tileSize\n",
    "        tileHeight = tileSize\n",
    "\n",
    "    for tile_info in ts.tileIterator(\n",
    "        region=dict(units=\"base_pixels\"),\n",
    "        scale=dict(magnification=magnification),\n",
    "        tile_size=dict(width=tileWidth, height=tileHeight),\n",
    "        format=large_image.tilesource.TILE_FORMAT_NUMPY\n",
    "    ):\n",
    "        if opType == \"tileHist\":\n",
    "            #            im_tile = np.array(tile_info[\"tile\"])\n",
    "            im_tile = tile_info[\"tile\"]\n",
    "            bytesRead += im_tile.size\n",
    "            \n",
    "            image_array = tile_info['tile']\n",
    "            avgColor  = np.mean(image_array, axis=(0,  1))\n",
    "\n",
    "            histData = {'topX':tile_info['gx'],'topY':tile_info['gy'],'width':tile_info['gwidth'],\n",
    "                        'height':tile_info['gheight'], 'localTileId': tile_info['tile_position']['position'],\n",
    "                       \"apiURL\": dsaApiUrl,   \"imageId\": imageInfo['imageId'],    \"imageName\": imageInfo['imageName'],\n",
    "                       \"average\": list(avgColor), \"featureType\": \"imgHistogram\"}\n",
    "\n",
    "            \n",
    "            for idx,c in enumerate(['red','green','blue']):\n",
    "                h = np.histogram(image_array[:,:,idx],bins=255,range=[0,255])\n",
    "                histData[c] =h[0].tolist()\n",
    "            gridData.append(histData)\n",
    "        tilesProcessed += 1\n",
    "        \n",
    "        \n",
    "    ## Export some of the stats for analtsis\n",
    "    computationStats[\"elapsedTime\"] = time.time() - st\n",
    "    computationStats[\"tilesProcessed\"] = tilesProcessed\n",
    "    computationStats[\"tileWidth\"] = tileWidth\n",
    "    computationStats[\"tileHeight\"] = tileHeight\n",
    "    computationStats[\"sizeX\"] = ts.sizeX\n",
    "    computationStats[\"sizeY\"] = ts.sizeY\n",
    "    computationStats[\"bytesRead\"] = bytesRead\n",
    "    computationStats[\"magnification\"] = magnification\n",
    "    computationStats[\"tileSizeParam\"] = tileSize\n",
    "    computationStats[\"ftxComputeTime\"] = time.time() - st\n",
    "    computationStats[\"featureType\"] = \"imgHistogram\"\n",
    "    computationStats[\"imageId\"] = imageInfo[\"imageId\"]\n",
    "    \n",
    "\n",
    "    return computationStats, gridData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ada1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51e248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://dsapostgisapi:82/addTileFeatures'\n",
    "\n",
    "ftrUrl= 'http://dsapostgisapi:82/addFeatureExtractionParams'\n",
    "\n",
    "for i in imageList:\n",
    "    for mag in [10,20]:\n",
    "        ## Add an endpoint to see if the features have already been computed for this image.\n",
    "        \n",
    "        for tsp in ['native']:\n",
    "        \n",
    "            imageInfo = lookupPostgisImageId(i, dsaApiUrl)\n",
    "    #         print(imageInfo)\n",
    "            paramSet = {'imageId': imageInfo['imageId'],'magnification': mag, 'tileSizeParam': tsp}\n",
    "            ftrLookupUrl= 'http://dsapostgisapi:82/lookupFeatureExtractionParams'\n",
    "\n",
    "            r = requests.post(ftrLookupUrl, params=paramSet)\n",
    "            ##Only want to compute features if we haven't run this set of params yet\n",
    "#             if not r.json():\n",
    "\n",
    "            stats,histData = generateRGBGrid(i,dsaApiUrl,magnification=mag,tileSize='native')\n",
    "            #print(stats)\n",
    "\n",
    "            r = requests.post(ftrUrl, json=stats)\n",
    "\n",
    "            ## Delete any ftxtract_id already in the database...\n",
    "            ftIdParams = {'imageId': imageInfo['imageId'], 'ftxtract_id': r.json()['ftxtract_id']}\n",
    "            dr = requests.delete(\"http://dsapostgisapi:82/deleteTileFeatures\", params = ftIdParams)\n",
    "            ## Also add the ftxtract_id that I just pulled into the histograms...\n",
    "            for h in histData:\n",
    "                h['paramSetId'] = r.json()['ftxtract_id']\n",
    "                h['ftxtract_id'] = r.json()['ftxtract_id']\n",
    "\n",
    "            for l in split_list(histData,1000):\n",
    "                r = requests.post(url,json=l)\n",
    "#             else:\n",
    "#                 print(\"Already computed features at \",mag,i)\n",
    "\n",
    "## Add logic to determine is all features/ rois that should be tehre, are there... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8801e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a177d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c38c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "\n",
    "# url = 'http://dsapostgisapi:82/addTileFeatures'\n",
    "\n",
    "\n",
    "# r = requests.post(url,json=histData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "histData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff05385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
